{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "226c4d34-cde8-4f80-8ce2-9982400cac4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree:\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 167573.9021\n",
      "- Mean Absolute Error: 109575.4248\n",
      "- R2 Score: 0.9562\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 444149.4470\n",
      "- Mean Absolute Error: 196151.8874\n",
      "- R2 Score: 0.7329\n",
      "===================================\n",
      "\n",
      "\n",
      "Random Forest Regressor:\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 166244.3404\n",
      "- Mean Absolute Error: 103721.1838\n",
      "- R2 Score: 0.9569\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 357737.5542\n",
      "- Mean Absolute Error: 166909.0154\n",
      "- R2 Score: 0.8267\n",
      "===================================\n",
      "\n",
      "\n",
      "                     model      train_mae     train_rmse  train_r2  \\\n",
      "0            Decision Tree  109575.424796  167573.902120  0.956214   \n",
      "1  Random Forest Regressor  103721.183772  166244.340385  0.956906   \n",
      "\n",
      "        test_mae      test_rmse   test_r2  \n",
      "0  196151.887368  444149.447013  0.732894  \n",
      "1  166909.015358  357737.554229  0.826717  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from category_encoders.binary import BinaryEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"car_dataset.csv\")\n",
    "\n",
    "# Use a sample of the data for faster processing\n",
    "df = df[:1000]\n",
    "\n",
    "# Define features and target\n",
    "X = df.drop(['selling_price'], axis=1)\n",
    "y = df['selling_price']\n",
    "\n",
    "# Define categorical features\n",
    "cat_features = [col for col in X.columns if X[col].dtype == 'object']\n",
    "\n",
    "# Define preprocessing steps\n",
    "num_features = X.select_dtypes(exclude=\"object\").columns\n",
    "onehot_columns = ['seller_type', 'fuel_type', 'transmission_type']\n",
    "binary_columns = ['car_name']\n",
    "\n",
    "numeric_transformer = StandardScaler()\n",
    "oh_transformer = OneHotEncoder()\n",
    "binary_transformer = BinaryEncoder()\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    [\n",
    "        (\"OneHotEncoder\", oh_transformer, onehot_columns),\n",
    "        (\"StandardScaler\", numeric_transformer, num_features),\n",
    "        (\"BinaryEncoder\", binary_transformer, binary_columns)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Separate dataset into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train.shape, X_test.shape\n",
    "\n",
    "# Transform the data\n",
    "X_train_transformed = preprocessor.fit_transform(X_train)\n",
    "X_test_transformed = preprocessor.transform(X_test)\n",
    "\n",
    "# Define evaluation function\n",
    "def evaluate_model(true, predicted):\n",
    "    mae = mean_absolute_error(true, predicted)\n",
    "    mse = mean_squared_error(true, predicted)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2_square = r2_score(true, predicted)\n",
    "    return mae, rmse, r2_square\n",
    "\n",
    "# Custom Decision Tree Implementation\n",
    "class DecisionTree:\n",
    "    def __init__(self, max_depth=None):\n",
    "        self.max_depth = max_depth\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # Convert DataFrame to NumPy array if necessary\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.values\n",
    "        if isinstance(y, pd.Series):\n",
    "            y = y.values\n",
    "        self.tree_ = self._build_tree(X, y, depth=0)\n",
    "    \n",
    "    def _build_tree(self, X, y, depth):\n",
    "        num_samples, num_features = X.shape\n",
    "        if num_samples <= 1 or (self.max_depth is not None and depth >= self.max_depth):\n",
    "            return np.mean(y)\n",
    "\n",
    "        best_split = self._find_best_split(X, y)\n",
    "        if best_split is None:\n",
    "            return np.mean(y)\n",
    "        \n",
    "        left_indices = X[:, best_split['feature']] <= best_split['value']\n",
    "        right_indices = X[:, best_split['feature']] > best_split['value']\n",
    "        \n",
    "        left_tree = self._build_tree(X[left_indices], y[left_indices], depth + 1)\n",
    "        right_tree = self._build_tree(X[right_indices], y[right_indices], depth + 1)\n",
    "        \n",
    "        return {'feature': best_split['feature'], 'value': best_split['value'], 'left': left_tree, 'right': right_tree}\n",
    "    \n",
    "    def _find_best_split(self, X, y):\n",
    "        best_split = None\n",
    "        best_mse = float('inf')\n",
    "        num_features = X.shape[1]\n",
    "\n",
    "        for feature in range(num_features):\n",
    "            values = np.unique(X[:, feature])\n",
    "            for value in values:\n",
    "                left_indices = X[:, feature] <= value\n",
    "                right_indices = X[:, feature] > value\n",
    "                \n",
    "                if len(y[left_indices]) == 0 or len(y[right_indices]) == 0:\n",
    "                    continue\n",
    "                \n",
    "                left_y = y[left_indices]\n",
    "                right_y = y[right_indices]\n",
    "                \n",
    "                mse = (np.var(left_y) * len(left_y) + np.var(right_y) * len(right_y)) / len(y)\n",
    "                \n",
    "                if mse < best_mse:\n",
    "                    best_split = {'feature': feature, 'value': value}\n",
    "                    best_mse = mse\n",
    "        \n",
    "        return best_split\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Convert DataFrame to NumPy array if necessary\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.values\n",
    "        return np.array([self._predict(sample, self.tree_) for sample in X])\n",
    "    \n",
    "    def _predict(self, sample, tree):\n",
    "        if not isinstance(tree, dict):\n",
    "            return tree\n",
    "        \n",
    "        if sample[tree['feature']] <= tree['value']:\n",
    "            return self._predict(sample, tree['left'])\n",
    "        else:\n",
    "            return self._predict(sample, tree['right'])\n",
    "\n",
    "# Custom Random Forest Implementation\n",
    "class RandomForest:\n",
    "    def __init__(self, n_estimators=100, max_depth=None):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_depth = max_depth\n",
    "        self.trees = []\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # Convert DataFrame to NumPy array if necessary\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.values\n",
    "        if isinstance(y, pd.Series):\n",
    "            y = y.values\n",
    "        for _ in range(self.n_estimators):\n",
    "            X_resampled, y_resampled = resample(X, y)\n",
    "            tree = DecisionTree(max_depth=self.max_depth)\n",
    "            tree.fit(X_resampled, y_resampled)\n",
    "            self.trees.append(tree)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        # Convert DataFrame to NumPy array if necessary\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.values\n",
    "        tree_predictions = np.array([tree.predict(X) for tree in self.trees])\n",
    "        return np.mean(tree_predictions, axis=0)\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    \"Decision Tree\": DecisionTree(max_depth=5),\n",
    "    \"Random Forest Regressor\": RandomForest(n_estimators=100, max_depth=5),\n",
    "}\n",
    "\n",
    "# Train and evaluate models\n",
    "results = []\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    # Train model\n",
    "    model.fit(X_train_transformed, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_train_pred = model.predict(X_train_transformed)\n",
    "    y_test_pred = model.predict(X_test_transformed)\n",
    "    \n",
    "    # Evaluate Train and Test dataset\n",
    "    model_train_mae, model_train_rmse, model_train_r2 = evaluate_model(y_train, y_train_pred)\n",
    "    model_test_mae, model_test_rmse, model_test_r2 = evaluate_model(y_test, y_test_pred)\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"{model_name}:\")\n",
    "    print('Model performance for Training set')\n",
    "    print(\"- Root Mean Squared Error: {:.4f}\".format(model_train_rmse))\n",
    "    print(\"- Mean Absolute Error: {:.4f}\".format(model_train_mae))\n",
    "    print(\"- R2 Score: {:.4f}\".format(model_train_r2))\n",
    "    print('----------------------------------')\n",
    "    print('Model performance for Test set')\n",
    "    print(\"- Root Mean Squared Error: {:.4f}\".format(model_test_rmse))\n",
    "    print(\"- Mean Absolute Error: {:.4f}\".format(model_test_mae))\n",
    "    print(\"- R2 Score: {:.4f}\".format(model_test_r2))\n",
    "    print('='*35)\n",
    "    print('\\n')\n",
    "\n",
    "    # Store results\n",
    "    results.append({\n",
    "        'model': model_name,\n",
    "        'train_mae': model_train_mae,\n",
    "        'train_rmse': model_train_rmse,\n",
    "        'train_r2': model_train_r2,\n",
    "        'test_mae': model_test_mae,\n",
    "        'test_rmse': model_test_rmse,\n",
    "        'test_r2': model_test_r2\n",
    "    })\n",
    "\n",
    "# Optional: Convert results to a DataFrame for easier analysis\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85dc0ce9-00af-4d2a-8a60-42c98b808856",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['preprocessor.pkl']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the preprocessor\n",
    "joblib.dump(preprocessor, 'preprocessor.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6cb4cdf1-8b52-4032-bc86-3b3eb43c0152",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['car_price_model.pkl']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the model\n",
    "joblib.dump(models['Random Forest Regressor'], 'car_price_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b831bc4-b7d2-4ecb-9f18-f272640c8827",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
